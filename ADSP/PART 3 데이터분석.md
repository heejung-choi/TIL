
# PART 3 데이터분석
                    
# 1장 데이터 분석 개요
### 데이터 처리
대기업은 데이터웨어하우스와 데이터마트를 통해 분석 데이터를 가져와서 사용한다. 
신규 시스템이나 DW에 포함되지 못한 자료의 경우, 기존 운영시스템이나 스테이징 영역과 ODS(Opering Data Store)에서 데이터를 가져와서 DW에서 가져온 내용과 결합하여 활용할 수 있다.
하지만 운영시스템에 직접 접근해 데이터를 활용하는 것은 매우 위험한 일이므로 거의 이루어지지 않고 있으며 
스테이징 영역의 데이터는 운영시스템에서 임시로 저장된 데이터이기 때문에 가급적이면 클렌징영역인 ODS에서 데이터 전처리를 해서 DW과 DM과 결합하여 활용하는 것이 가장 이상적이다.

### 모델링 성능을 평가함에 있어 데이터마이닝에서 활용하는 평가기준
데이터마이닝은 정확도, 정밀도, 디렉트레이트 리프트 등의 값으로 판단한다.
시물레이션에서는 Throughput, Average Waiting Time, Average Queue Length, Time in System 등의 지표가 활용된다,

### 탐색적 자료 분석(EDA)
다양한 차원과 값을 조합해가며 특이한 점이나 의미있는 사실을 도출하고 분석의 최종 목적을 달성해나가는 과정으로 데이터의 특징과 내자하는 구조적 관계를 알아내기 위한 기법들의 통칭이다.
 
- EDA의 4가지 주제 (그잔저자)
 그래프를 통한 현시성, 잔차계산, 저항성의 강조, 자료변수의 재표현

# 2장 R 프로그래밍 기초

- R의 데이터 구조 중 벡터에 대한 설명으로 적절한 것은?

    - 벡터는 하나의 스칼라 값 또는 하나 이상의 스칼라 원소들을 갖는 단순한 형태의 집합이다.

- 벡터와 리스트의 차이

    - 벡터: 여러개의 원소를 가지는 하나의 변수로 한 벡터의 모든 원소는 같은 자료형 또는 모드를 가진다.

    - 리스트: 다른 프로그래밍 언어에서 사전, 해시, 탐색표와 유사하며 R에서는 리스트를 인덱싱 할 수 있는 장점을 가지고 있다. 또한 리스트는 여러 자료형의 원소들이 포함 될 수 있다.

- R의 Summary 함수

    - 연속형 변수의 경우 4분위수, 최소값, 최대값, 중앙값, 평균 등을 출력하고 범주형 변수의 경우 각 범주에 대한 빈도수를 출력하여 데이터의 분포를 파악할 수 있게 한다. 
    - 또한 수치형 변수의 경우 최대값, 최소값, 평균, 1사분위수, 2사분위수(중앙값), 3사분위수를 출력하며 명목형변수의 경우 명목값, 데이터의 개수를 출력하는 함수이다.

- R의 데이터구조 중 2차원 목록 데이터 구조이면서 각 열이 서로 다른 데이터 타입을 가질 수 있는 데이터 구조는?
    - 데이터프레임: 데이터프레임은 표 형태의 데이터 구조이며, 각 열은 서로 다른 데이터 형식을 가질 수 있다.

- 해당 코드가 의미하는 것은?
    - mean(x, na.rm=T) : na.rm은 결측치를 제외하느냐에 대한 물음이며, T는 TRUE로 결측치를 제외하겠다는 의미이다.
    - R에서 결측값을 가르키는 것은 NA 이다.

## R에서 사용하는 데이터 set의 형태

### 벡터(vector)
R은 실수, 복소수, 문자열, 논리값 등의 기본 데이터를 하나씩 단독으로 다루는 것이 아니라 같은 종류의 데이터를 여러개 묶은 벡터 형식으로 다룬다. 
벡터를 만드는 가장 간단한 방법은 함수 c()를 이용하는 방법이다. 
함수 c()의 인수 값으로 벡터에 넣고 싶은 값들을 열거하면 목적하는 벡터를 만들 수 있다.

### 행렬(matrix)
벡터는 원소를 단지 1열로 열거해놓은 것 뿐이지만, 실제 데이터는 행과 열로 이루어진 표 형식을 따르는 것이 많다. 
이러한 데이터 형식을 R에서는 행렬이라 하고, 표 형식의 데이터에 대한 분석함수를 이용하기 위해서는 미리 행렬화 시킬 필요가 있다. 
행렬은 함수 matrix()를 이용해 바탕이 되는 벡터에 행의 수 혹은 열의 수에 대한 정보를 추가함으로써 만들 수 있다.

### 리스트(list)
리스트는 벡터나 행렬을 한꺼번에 취급할 수 있는 형식이다. -> 데이터 타입이 같지 않는 객체들을 하나의 객체로 묶어놓을 수 있는 자료구조

복수의 관련된 벡터나 행렬을 하나의 리스트에 정리하여 보존할 수 있으며 함수 list()를 이용하여 작성한다. 
함수의 인수 값은 리스트에 포함되는 벡터나 행렬을 지정하거나, 데이터의 참조용 이름을 부여하여 사용할 수도 있다.

### 재활용 규칙
길이가 서로 다른 두 벡터에 대해 연산을 할 때, R은 짧은 벡터의 처음으로 돌아가 연산이 끝날 때 까지 원소들을 재활용한다.

### 데이터프레임(data frame)
데이터프레임은 R에서 분석을 수행할 때 가장 빈번히 사용되는 형식이다.
외부파일로부터 R에 데이터를 불러올 때 사용하는 함수 군은 불러들인 데이터를 모두 데이터프레임으로 변환시키기 때문이다.
데이터프레임은 리스트의 한 종류로 리스트에 포함된 모든 값이 길이가 같은 벡터일 때, 혹은 행의 수, 열의 수가 같은 행렬에 한해
그 리스트를 함수 data.frame()을 이용해 데이터프레임으로 변환시킬 수 있다.

### R에서 제공하는 데이터 가공, 처리를 위한 패키지의 설명으로 가장 부적절 한 것은?
data.table 패키지는 데이터 프레임 처리함수인 ddply함수를 제공한다.
-> data.table 패키지는 큰 데이터를 탐색, 연산, 병합하는데 아주 유용하다.  ddply는 plyr패키지에서 지원한다.

나머지는 적절한 것
reshape 패키지는 melt와 cast를 이용하여 데이터를 재구성할 수 있다.
sqldf 패키지는 r에서 표준 sql명령을 실행하고 결과를 가져올 수 있다.
plyr 패키지는 데이터의 분리, 결합 등 필수적인 데이터 처리 기능을 제공한다.

### 변수 결합
cbind (dfm1, dfm2, by ="Tname") : 열결합(왼쪽+오른쪽) -> 유의사항: cbind는 행의 개수가 동일해야 함 
rbind (dfm1, dfm2, by ="Tname") : 행결합(위쪽+아래쪽) -> 유의사항: rbind는 열의 개수와 열의 이름이 동일해야함
merge (dfm1, dfm2, by ="Tname") : 동일 key 결합
subset (dfm1, dfm2, by ="Tname") : 특정 조건에 맞는 변수 추출

### mx = matrix(c(1,2,3,4,5,6), ncol=2, byrow=T)의 결과는?
ncol -> 열의 개수를 지정 / nrow -> 행의 개수를 지정
```     
     [,1] [,2]
[1,]  1     2
[2,]  3     4
[3,]  5     6
```
#### 2019/08/23 을 "2019-08-23"으로 나타내는 코드
as.Date('08/23/2019','%m/%d/%Y')

#### R에서 새로운 패키지를 설치 및 사용하고자 할 때 명령어
install.packages("패키지명") -> library(패키지명)

# 3장 데이터 마트

### 데이터 마트

데이터 웨어하우스와 사용자 사이의 중간층에 위치한 것으로 하나의 주제 또는 하나의 부서 중심의 데이터 웨어하우스라고 할 수 있다. 데이터 마트 내 
대부분의 데이터는 데이터 웨어하우스로부터 복제되지만 자체적으로 수집될 수도 있으며, 관계형 데이터 베이스나 다차원 데이터 베이스를 이용하여 구축한다.

 ex) 1개의 데이터워어하우스에서 -> 지역, 고객, 마케팅, 재무, 협력사 데이터마트를 생성한다.

데이터 마트를 만들 때 가장 중요한 것은 데이터웨어하우스에서 받아오는 데이터이다. 받아온 데이터를 처리과정을 통해 분석에 적절하게 활용할 수 있는 자료로 변환해야 한다.


### 요약변수

데이터를 특정 기준에 따라 사칙연산을 통해 만들어 낸 변수로 수집된 정보를 분석에 맞게 종합한 변수이다. 또한 데이터 마트에서 가장 기본적인 변수로 총 구매금액, 금액, 횟수 등 데이터 분석을 위해 만들어지는 변수이다.

요약변수를 잘 만든다면 분석의 중요한 변수로 사용될 수 있고 많은 모델에 공통으로 사용될 수 있어 재활용성이 높다.

예시(기간별 구매금액 및 횟수여부, 위클리쇼퍼, 상품별구매금액 및 횟수여부, 상품별 구매순서, 유통채널별 구매 금액, 단어 빈도, 초기 행동변수, 트렌드변수, 결측값과 이상값 처리, 연속형 변수의 구간화 등)

### 파생변수

사용자의 노하우를 기반으로 새롭게 만들어 낸 변수로 사용자가 특정 조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여한 변수이다. 매우 주관적일 수 잇으므로 논리적 타당성을 갖추어 개발해야 한다.

예시(근무시간 구매지수, 주 구매 매장 변수, 주 활동지역 변수, 주 구매상품 변수, 선호하는 가격대 변수, 시즌 선호고객 변수 등)

### R패키지 

- reshape의 활용
    - melt(): 녹이는 함수-> 원데이터 형태로 만드는 함수로 쉬운 casting을 위해 적당한 형태로 만들어주는 함수이다.
    - cast(): 모양을 만드는 함수-> 요약 형태로 만드는 함수로 데이터를 원하는 형태로 계산 또는 변형시켜주는 함수이다.

- sqldf
R에서 sql의 명령어를 사용가능하게 해주는 패키지 이다. (SAS의 PROC SQL과 같은 역할)

- data.table  (데이터 프레임과 비교하여 알아두어야 한다.)
R에서 가장 많이 사용하는 데이터 핸들링 패키지 중 하나이다. 큰 데이터를 탐색, 연산, 병합하는데 아주 유용하다.
기존 data.frame 방식보다 월등히 빠른 속도이다. 특정 Column을 Key 값으로 색인을 지정한 후 데이터를 처리한다.
빠른 그루핑과 Ordering 짧은 문장지원 측면에서 데이터 프레임보다 유용하다.

- plyr
Multi-Core를 사용하여 반복문을 사용하지 않고도 매우 간단하고 빠르게 처리할 수 있는 데이터 처리함수를 포함하고 있는 패키지이다.
데이터를 분할하고 분할된 결과에 함수를 적용한 뒤 결과를 재조합하는 함수를 포함한다.
-> r에서 반복문을 다중으로 사용할 경우 계산시간이 떨어지는 단점이 있는데 이를 보완해준다.

### 데이터 가공
head: 시작 6개 record 조회
tail: 마지막 6개 record 조회
summary: 수치형변수(최댓값, 최솟값, 평균, 1사분위수, 2사분위수(중앙값), 3사분위수), 명목형 변수(명목값, 데이터 개수)

### 변수의 구간화
연속형 변수를 분석 목적에 맞게 활용하기 위해 구간화 하여 모델링에 적용한다.

- 변수 구간화 방법
1) Binning : 신용평가 모형의 개발에서 연속형 변수를 범주형 변수로 구간화 하는데 자주 활용되고 있는 방법이다.
2) 의사결정나무: 의사결정나무 모형을 사용하여 입력변수들을 구간화 한다.

### 결측값 처리 방법
- 단순대치법(Single Imputation)
1) Completes Analysis 
결측값이 존재하는 레코드를 삭제한다. 또한 불완전자료를 모두 삭제하고 완전한 관측치만으로 자료를 분석하는 방법이다. 그러나 부분적 관측자료를 사용하므로 통계적 추론의 타당성의 문제가 있다.

2) 평균대치법(Mean Imputation)
관측 또는 실험을 통해 얻어진 데이터의 평균으로 대치한다.

3) 단순확률 대치법(Single Stochastic Imputation)
평균대치법에서 추정량 표준오차의 과소 추정문제를 보완하고자 고안한 방법

4) 다중 대치법(Multiple Imputation)
단순 대치법을 한 번만 하지 않고 m번의 대치를 통해 m개의 가상적 완전 자료를 만드는 것이다. 다중대치법은 추정량의 표준오차의 과소추정 또는 계산의 난해성 문제가 보완된 방법이다.

### 이상값
이상값은 의도치않게 잘못 입력된 경우, 의도하지 않게 입력되었으나 분석 목적에 부합하지 않아 제거해야하는 경우, 의도하지 않은 형상이지만 분석에 포함해야 하는 경우, 의도된 이상값인 경우 등이 있다.
이상값을 꼭 제거해야 하는 것은 아니기 때문에 종류에 따라 적절한 판단이 필요하다.

### 이상값 인식 방법
**1) ESD (Extreme Studentized Deviation)**
- 평균으로부터 3 표준편차 떨어진 값

2) 기하평균 - 2.5 * 표준편차 < data < 기하평균 + 2.5 * 표준편차

3) 사분위수 이용하여 제거하기 (상자그림의 outer fence 밖에 있는 값 제거)
- 이상값 정의 :Q1 - 1.5(Q3-Q1)<data>Q3 + 1.5(Q3-Q1)를 벗어나는 데이터

### 극단값
극단값 절단 방법을 활용해 데이터를 제거하는 것 보다는 극단값 조정 방법을 이용하는 것이 데이터 손실율도 적고 설명력도 높아진다.

1) 극단값 절단 방법
- 기하평균을 이용한 제거
- 하단, 상단 %를 이용한 제거

2) 극단값 조정 방법
- 상한값과 하한값을 벗어나는 값들을 하한, 상한값으로 바꾸어 활용하는 방법이다.
<br>
<br>
# 4장 통계분석
### 1절 통계분석의 이해
조사 또는 실험을 통해 데이터를 확보, 조사대상에 따라 총조사와 표본조사로 구분한다.

가. 총조사 / 전수조사

대상집단 모두를 조사하는데 많은 비용과 시간이 소요되므로 특별한 경우를 제외하고는 사용되지 않는다.

나. 표본조사 (Sampling)

대부분의 설문조사가 표본조사로 진행되며 모집단에서 샘플을 추출하여 진행하는 조사이다.
- 모집단(Population): 조사하고자 하는 대상 집단 전체
- 원소(Element): 모집단을 구성하는 개체
- 표본(Sample): 조사하기 위해 추출한 모집단의 일부 원소
- 모수(Parameter): 표본 관측에 의해 구하고자 하는 모집단에 대한 정보

**다. 표본추출 방법**

표본추출방법 4가지 암기하기(한글,영어 용어 모두)
1) 단순랜덤 추출법(Simple Random Sampling)

각 샘플에 번호를 부여하여 임의의 n개를 추출하는 방법으로 각 샘플은 선택될 확률이 동일하다.

2) 계통 추출법(Systematic Sampling)

단순랜덤추출법의 변형된 방식으로 번호를 부여한 샘플을 나열하여 K개씩 (K=N/n) n개의 구간으로 나누고 첫구간(1,2,...,K)에서 하나를 임의로 선택한 후에 K개씩 띄워서 n개의 표본을 선택한다. 즉, 임의의 위치에서 매 K번째 항목을 추출하는 방법이다.

3) 집락추출법(Cluster Random Sampling)

군집을 구분하고 군집별로 단순랜덤 추출법을 수행한 후, 모든 자료를 활용하거나 샘플링하는 방법이다.

4) 층화추출법(Stratified Random Sampling)
   이질적인 원소들로 구성된 모집단에서 각 계층을 고루 대표할 수 있도록 표본을 추출하는 방법으로, 유사한 원소끼리 몇개의 층으로 나누어 각 층에서 랜덤 추출하는 방법이다.

**라. 측정**

2회에 1번꼴로 출제/ 각 척도의 정의와 예시를 반드시 숙지

표본조사나 실험을 실시하는 과정에서 추출된 원소들이나 실험 단위로부터 주어진 목적에 적합하도록 관측해 자료를 얻는 것이다.

2) 측정방법
1. 질적척도 : 범주형 자료, 숫자들의 크기 차이가 계산되지 않는 척도
- 명목척도: 특정 대상이 어느 집단에 속하는지 분류할 때 사용 (성별, 출생지 구분)
- 순서척도(서열척도): 측정 대상의 서열관계를 관측하는 척도(만족도, 선호도, 학년, 신용등급)

2. 양적척도: 수치형자료, 숫자들의 크기 차이를 계산할 수 있는 척도
- 구간척도(등간척도): 측정 대상이 갖고있는 속성의 양을 측정하는 것으로 구간이나 구간 사이의 간격이 의미가 있는 자료(온도, 지수)
- 비율척도: 간격(차이)에 대한 비율이 의미를 가지는 자료, 절대적인 기준인 0이 존재하고 사칙연산이 가능하며 제일 많은 정보를 가지는 척도(무게, 나이, 시간, 거리)

서열척도는 명목척도와 달리 매겨진 숫자의 크기를 의미있게 활용할 수 있다.
구간척도는 절대적 크기는 측정할 수 없기 때문에 사칙연산 중 더하기와 빼기는 가능하지만 비율처럼 곱하거나 나누는 것은 불가능하다.

### 확률분포
1) 이산형 확률변수

0이 아닌 확률값을 갖는 확률 변수를 셀 수 있는경우(확률질량함수)
이산형 확률변수의 예시: 동전 2개를 던져서 앞/뒷면이 나오는 경우의 수

가) 베르누이 확률분포: 결과가 2개만 나오는 경우(동전던지기, 시험합격/불합격)

나) 이항분포: 베르누이 시행을 n번 반복했을 때 K번 성공할 확률(추신수가 경기에서 5번타석에 들어와 3번 안타를 칠 확률
)

다) 기하분포: 성공확률이 P인 베르누이 시행에서 첫 번째 성공이 있기까지 X번 실패할 확률

라) 다항분포: 이항분포를 확장한 것으로 세가지 이상의 결과를 가지는 반복시행에서 발생하는 확률분포

마) 포아송분포: 시간과 공간 내에서 발생하는 사건의 발생횟수에 대한 확률분포
ex) 책에 오타가 5page 당 10개씩 나온다고 할 때, 한 페이지에 오타가 3개 나올 확률

2) 연속형 확률변수

가능한 값이 실수의 어느 특정구간 전체에 해당하는 확률변수

가) 균일분포: 모든 확률 변수 X가 균일한 확률을 가지는 확률분포

나) 정규분포: 평균이 μ이고 표준편차가 σ 인 X의 확률밀도함수로 표준편차가 클 경우 퍼져보이는 그래프가 나타난다.

## 2절 기초 통계분석
### 산점도에서 확인할 사항
두 변수 사이에 선형관계(직선관계)가 성립하는가?
두 변수 사이에 함수관계(직선관계 또는 곡선관계)가 성립하는가?
이상값이 존재하는가?
몇 개의 집단으로 구분(층별)되는가?

## 3절 회귀분석
가. 회귀분석의 정의

회귀분석은 하나나 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법이다. 변수들 사이의 인과관계를 밝히고 모형을 적합하여 관심있는 변수를 예측하거나 추론하기 위한 분석방법이다.

독립변수 개수가 하나면 단순선형회귀분석, 독립변수 개수가 두개 이상이면 다중선형 회귀분석으로 분류할 수 있다.

나. 회귀분석의 변수
영향을 받는 변수(Y): 반응변수, 종속변수, 결과변수
영향을 주는 변수(X): 설명변수, 독립변수, 예측변수

### 회귀계수의 검정
회귀계수 B1이 0이면 입력변수 x와 출력변수 y 사이에는 아무런 인과관계가 없다.
회귀계수 B1이 0이면 적합된 추정식은 아무 의미가 없게 된다.

### 단순선형회귀분석
하나의 독립변수가 종속변수에 미치는 영향을 추정할 수 있는 통계기법이다.

1) 회귀분석에서의 검토사항

- 회귀계수들이 유의미한가? 해당 계수의 t-통계량의 p-값이 0.05보다 작으면 해당 회귀계수가 통계적으로 유의하다고 볼 수 있다.
- 모형이 얼마나 설명력을 갖는가? 결정계수를 확인한다. 결정계수는 0~1의 값을 가지며, 높은 값을 가질수록 추정된 회귀식의 설명력이 높다.
- 모형이 데이터를 잘 적합하고 있는가? 잔차를 그래프로 그리고 회귀진단을 한다.

2) 회귀계수의 검정
ex) 예제
10년간 에어컨 예약대수와 판매대수에 대한 단순 회귀분석을 실시하였다.
결과:
p-value: 0.0005805
-> x의 회귀계수인 t-통계량에 대한 p-값이 0.000581로 나타나 유의수준인 0.005보다 작으므로 회귀계수의 추정치들이 통계적으로 유의하다.
multiple R-squared: 0.8341
-> 결정계수는 0.8341로 높게 나타나 이 회귀식이 데이터를 적절하게 설명하고 있다고는 할 수 있다.
결정계수가 높아 데이터의 설명력이 높고 회귀분석결과에서 회귀식과 회귀계수들이 통계적으로 유의하므로 에어컨 판매대수를 에어컨 예약대수로 추정할 수 있다.
Confficients:(계수)
(intercept)        x
      6.409    1.529
-> 회귀분석 결과 "판매대수 = 6.409 + 1.5295 * 예약대수의 회귀식을 구할 수 있다."

### 다중선형회귀분석
1) 모형의 통계적 유의성
모형의 통계적 유의성은 F-통계량으로 확인한다.
유의수준 5%하에서 F-통계량의 p-값이 0.05보다 작으면 추정된 회귀식은 통계적으로 유의하다고 볼 수 있다.
F-통계량이 크면 p-value가 0.05보다 작아지고 이렇게 되면 귀무가설을 기각한다. 즉, 모형이 유의하다고 결론지을 수 있다.

2) 회귀계수의 유의성
회귀계수의 유의성은 단변량회귀분석의 회귀계수 유의성 검토와 같이 t-통계량을 통해 확인한다.
모든 회귀계수의 유의성이 통계적으로 검증되어야 선택한 변수들의 조합으로 모형을 활용할 수 있다.

3) 모형의 설명력
결정계수나 수정된 결정계수를 확인한다.

4) 모형의 적합성
모형이 데이터를 잘 적합하고 있는지 잔차와 종속변수의 산점도로 확인한다.

5) 데이터가 전제하는 가정을 만족시키는가?
선형성, 독립성, 등분산성, 비상관성, 정상성

6) 데이터가 전제하는 가정을 만족시키는가?
선형성, 독립성, 등분산성, 비상관성, 정상성

7) R프로그램을 통한 회귀분석
MASS 패키지의 "Cars93"라는 데이터셋의 가격을 종속변수로 선정하고 엔진크기, RPM, 무게를 이용해서 다중회귀분석을 실시한다.
```
> library(MASS)
> lm(Price~EngineSize+RPM+Weight, data=Cars93)
Call:
lm(formula = Price ~ EngineSize + RPM + Weight, data = Cars93)

Coefficients:
(Intercept)   EngineSize          RPM       Weight  
 -51.793292     4.305387     0.007096     0.007271  

> summary (lm(Price~EngineSize+RPM+Weight, data=Cars93))

Call:
lm(formula = Price ~ EngineSize + RPM + Weight, data = Cars93)

Residuals:
    Min      1Q  Median      3Q     Max 
-10.511  -3.806  -0.300   1.447  35.255 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -51.793292   9.106309  -5.688 1.62e-07 ***
EngineSize    4.305387   1.324961   3.249  0.00163 ** 
RPM           0.007096   0.001363   5.208 1.22e-06 ***
Weight        0.007271   0.002157   3.372  0.00111 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.504 on 89 degrees of freedom
Multiple R-squared:  0.5614,	Adjusted R-squared:  0.5467 
F-statistic: 37.98 on 3 and 89 DF,  p-value: 6.746e-16
```
Residuals(잔차)
    Min      1Q  Median      3Q     Max 
-10.511  -3.806  -0.300   1.447  35.255
잔차는 예측값과 실제값의 차이를 나타낸다.
잔차의 최솟값(Min), 사분위수(1Q, Median, 3Q), 최댓값(Max)을 보여준다.  

Estimate(데이터로부터 얻은 계수의 추정치)
EngineSize 4.305387 -> 가격이 1 오르면 EngineSize가 4.305387 오른다.

추정치의 오른쪽 끝의 Pr(>|t|)는 모집단에서 계수가 0일 때, 현재와 같은 크기의 표본에서 이러한 계수가 추정될 확률인 p값을 나타낸다. 
이 확률이 매우 작다는 것은, 모집단에서 EngineSize 계수가 정확히 4.305387가 아니더라도 현재의 표본과 비슷하게 0보다 큰 어떤 범위에 있을 가능성이 높다는 것을 의미한다. 
보통 5%와 같은 유의수준을 정하여 p값이 그보다 작으면(p < 0.05), "통계적으로 유의미하다"라고 한다.
-> 회귀계수들의 p-값들이 0.05보다 작으므로 회귀계수들의 추정치들이 통계적으로 유의하다.

Multiple R-squared(결정계수):  0.5614 
Adjusted R-squared(수정된 결정계수):  0.5467
결정계수와 수정된 결정계수는 0.0564, 0.5467로 조금 낮게 나타나나 이 회귀식이 데이터를 적절하게 설명하고 있다고는 할 수 없다.
1에 가까울 수록 설명력이 높은 것으로 가격을 56% 설명한다고 볼 수 있다.

F-statistic: 37.98 on 3 and 89 DF,  p-value: 6.746e-16
F- 통계량은 37.98이며 유의확률 p-value 값이 6.746e-16로 유의수준 5%하에서 추정된 회귀모형이 통계적으로 매우 유의하다.

결정계수가 낮아 데이터의 설명력은 낮지만 회귀분석 결과에서 회귀식과 회귀계수들이 통계적으로 유의하여 자동차의 가격을 엔진의 크기와 RPM, 무게로 추정할 수 있다.

---
잔차의 다른 예시 해설
Min      1Q  Median      3Q     Max
-29.069  -9.525  -2.272   9.215  43.201
중앙값(median)이 0에 가깝고, 1사분위 점수(Q1)와 3사분위 점수(Q3)가 거의 대칭을 이루고 있으므로, 잔차가 정규분포에서 거의 벗어나지 않았다고 볼 수 있다.


8) 로지스틱회귀분석 예제
로지스틱회귀분석: 독립변수의 선행 결합을 이용하여 사건의 발생 가능성을 예측할 때 사용하는 통계기법

- 데이터 설명
림프절이 전립선 암에 대해 양성인지 여부를 예측하는 데이터
양성여부(r) -> 전립선암에 대한 양성 여부
age(연령), stage(질병단계), grade(종양등급-진행의 정도), x-ray(x선 결과), acid(특정한 부위에 종양이 전이되었을 때 상승되는 혈청의 인산염값)
```
library(boot)
data(nodal)
a<-c(2,3,4,5,6,7)
data <- nodal[,a]
glmModel <-glm(r~., data, family ="binomial")
summary(glmModel)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)  -3.0794     0.9868  -3.121   0.0018 **
aged         -0.2917     0.7540  -0.387   0.6988   
stage         1.3729     0.7838   1.752   0.0799 . 
grade         0.8720     0.8156   1.069   0.2850   
xray          1.8008     0.8104   2.222   0.0263 * 
acid          1.6839     0.7915   2.128   0.0334 * 

```
2번째 변수인 양성여부를 종속변수로 두고 5개의 변수를 독립변수로 로지스틱회귀분석을 실시한 결과 
age와 grade는 유의수준 5%하에서 유의하지 않아 이를 제외한 3개 변수 stage,xray,acid를 활용해서 모형을 개발한다.

```
a<-c(2,4,6,7)
data <- nodal[,a]
glmModel <-glm(r~., data, family ="binomial")
summary(glmModel)

Call:
glm(formula = r ~ ., family = "binomial", data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.1231  -0.6620  -0.3039   0.4710   2.4892  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -3.0518     0.8420  -3.624  0.00029 ***
stage         1.6453     0.7297   2.255  0.02414 *  
xray          1.9116     0.7771   2.460  0.01390 *  
acid          1.6378     0.7539   2.172  0.02983 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 70.252  on 52  degrees of freedom
Residual deviance: 49.180  on 49  degrees of freedom
AIC: 57.18

Number of Fisher Scoring iterations: 5
```
stage,xray,acid의 추정계수는 유의수준 5%하에서 유의하게 나타난다.(Pr(>|z|))
따라서 p(r=1)=1/(1+e-(-3.05+1.65stage+1.91xray+1.64acid))의 선형식이 가능하다.

#### 최적 회귀방정식
- 단계적 변수 선택 
1) 전진선택법 : 절편만 있는 상수모형으로부터 시작해 중요하다고 생각되는 설명변수부터 차례로 모형에 추가한다.
전진선택법은 이해하기 쉽고 변수의 개수가 많은 경우에도 사용이 가능하다. 그러나 변수의 작은 변동에도 결과가 크게 달라져 안정성이 부족하다.
- step함수를 이용한 전진선택법의 적용(**direction = "forward"**)
step(lm(y~1),data=df), score=list(lower=~1,upper=~x1+x2+x3+x4), direction = "forward")

2) 후진제거법 : 독립변수 후보 모두를 포함한 모형에서 출발해 가장 적은 영향을 주는 변수부터 하나씩 제거하면서 더이상 제거할 변수가 없을 때의 모형을 선택한다.
후진제거법은 전체 변수들의 정보를 이용하는 장점이 있는 반면 변수의 개수가 많은 경우 사용하기 어렵다.
- step함수를 이용한 후진선택법의 적용(**direction = "backward"**)
  step(lm(lpsa~., data=Data[,-ncol(data)]),lpsa~1, direction="backward")

3)단계선택법 : 전진선택법에 의해 변수를 추가하면서 새롭게 추가된 변수에 기인해 기존 변수의 중요도가 약화되면 해당 변수를 제거하는 등 
단계별로 추가 또는 제거되는 변수의 여부를 검토해 더 이상 없을 때 중단한다.

- 벌점화된 선택기준
모형의 복잡도에 벌점을 주는 방법으로 AIC 방법과 BIC 방법이 주로 사용된다. 
가장 최적화된 모형을 선택하기 위해서는 AIC,BIC가 최소가 되는 모형을 선택해야 한다.


## 4절 시계열분석
가. 개요

시간의 흐름에 따라 관찰된 데이터를 시계열 데이터 또는 시계열 자료라고 한다. 주식가격 데이터, 실업률, 기후데이터 등 우리 주위에서 많이 찾아볼 수 있다.

나. 시계열 자료의 종류

1) 비정상성 시계열 자료: 시계열 분석을 실시할 때 다루기 어려운 자료로 대부분의 시계열 자료가 이에 해당
2) 정상성 시계열 자료: 비정상 시계열을 핸들링해 다루기 쉬운 시계열 자료로 변환한 자료이다.

다. 정상성

정상성은 평균이 일정할 때, 분산이 일정할 때, 공분산도 단지 시차에만 의존하고 실제 특정 시점 t,s에는 의존하지 않을 때 만족한다.

- 평균이 일정할 경우: 모든 시점에 대해 일정한 평균을 가진다. 평균이 일정하지 않은 시계열은 차분을 통해 정상화할 수 있다.
- 분산이 일정: 분산도 시점에 의존하지 않고 일정해야 한다. 분산이 일정하지 않을 경우 변환을 통해 정상화 할 수 있다.
- 공분산도 단지 시차에만 의존, 실제 특정 시점 t,s에는 의존하지 않는다.

### 5절 다차원척도법
다차원척도법은 군집분석과 같이 개체들을 대상으로 변수들을 측정한 후 개체들 사이의 유사성/비유사성을 측정하여 개체들을 2차원 또는 3차원 공간상에 점으로 표현하는 분석방법이다.
군집분석은 개체들간의 비유사성을 이용하여 동일한 그룹들로 분류하는 것이 목적인 반면,
다차원척도법은 개체들의 비유사성을 이용하여 2차원 공간상에 점으로 표시하고 개체들 사이의 집단화를 시각적으로 표현하는것을 목적으로 헌다.

- 다차원척도법 방법
  개체들의 거리 계산에는 유클리드 거리행렬을 활용한다.

### 주성분 분석
여려 변수들의 변량을 '주성분'이라는 서로 상관성이 높은 변수들의 선형 결합으로 만들어 기존의 상관성이 높은 변수들을 요약, 축소하는 기법이다.
첫번째 주성분으로 전체 변동을 가장 많이 설명할 수 있도록 하고,
두번째 주성분으로는 첫번째 주성분과는 상관성이 없어서 첫번째 주성분이 설명하지 못하는 나머지 변동을 정보의 손실없이 가장 많이 설명할 수 있도록 변수들의 선형조합을 만든다,.

- 주성분분석의 목적
  여러 변수들 간에 내재하는 상관관계, 연관성을 이용해 소수의 주성분으로 차원을 축소함으로써 데이터를 이해하기 쉽고 관리하기 쉽게 해준다.